{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5166d429",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b55852c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import getpass\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34740873",
   "metadata": {},
   "source": [
    "## Initialising the driver + logging into Linkedin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "014e4f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def driver():\n",
    "    user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'\n",
    "    s = Service(ChromeDriverManager().install())\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--ignore-certificate-errors')\n",
    "    options.add_argument('--incognito')\n",
    "    options.add_argument(\"headless\")\n",
    "    options.add_argument(f'user-agent={user_agent}')\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    options.binary_location = '/Applications/Brave Browser.app/Contents/MacOS/Brave Browser'\n",
    "    driver = webdriver.Chrome(service=s, options=options)\n",
    "\n",
    "def linkedin_login():\n",
    "    mail = str(getpass.getpass('Login email? '))\n",
    "    pw = str(getpass.getpass('Password? '))\n",
    "    driver.get('https://www.linkedin.com')\n",
    "    username = driver.find_element(By.ID, 'session_key').send_keys(mail)\n",
    "    password = driver.find_element(By.ID, 'session_password').send_keys(pw)\n",
    "    login_button = driver.find_element(By.CLASS_NAME,'sign-in-form__submit-button')\n",
    "    login_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3621512",
   "metadata": {},
   "source": [
    "## Data analyst positions in Barcelona published last month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d084f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_analyst():\n",
    "    driver()\n",
    "    linkedin_login()\n",
    "    titles = []\n",
    "    companies = []\n",
    "    locations = []\n",
    "    modalities = []\n",
    "    descriptions = []\n",
    "    for i in tqdm(range(0, 976, 25)):\n",
    "        driver.get(f'''https://www.linkedin.com/jobs/search/?f_TPR=r2592000&geoId=107025191&keywords=data%20analyst&location=Barcelona%2C%20Catalonia%2C%20Spain&start={i}''')\n",
    "        time.sleep(random.randint(3, 5))\n",
    "        all_listings = []\n",
    "        keep_scrolling = True\n",
    "\n",
    "        while keep_scrolling:\n",
    "            listings = driver.find_elements(By.CSS_SELECTOR,\".job-card-list__title\")\n",
    "            if set(listings) == set(all_listings):\n",
    "                keep_scrolling = False\n",
    "            else:\n",
    "                new_listings = list(set(listings) - set(all_listings))\n",
    "                #print(len(new_listings))\n",
    "                for listing in new_listings:\n",
    "                    all_listings.append(listing)\n",
    "                    try:\n",
    "                        driver.execute_script(\"arguments[0].scrollIntoView({behavior: 'smooth'});\", listing)\n",
    "                        time.sleep(random.randint(1, 3))\n",
    "                        listing.click()\n",
    "                        time.sleep(random.randint(2, 5))\n",
    "                        page_source = driver.page_source\n",
    "                        soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "                        try:\n",
    "                            title = driver.find_element(By.XPATH, \"//*[starts-with(@id, 'ember')]/h2\").text\n",
    "                            if 'data' in title.lower() or 'datos' in title.lower():\n",
    "                                titles.append(title)\n",
    "                                try:\n",
    "                                    company = driver.find_element(By.XPATH, \"//*[contains(@class, 'ember-view t-black t-normal')]\").text\n",
    "                                    companies.append(company)\n",
    "                                except NoSuchElementException:\n",
    "                                    companies.append('Unknown')\n",
    "                                    #driver.save_screenshot(\"screenshot.png\")\n",
    "                                try:\n",
    "                                    location = soup.select('body > div.application-outlet > div.authentication-outlet > div.job-search-ext > div.jobs-search-two-pane__wrapper > div > section.jobs-search__right-rail > div > div > div:nth-child(1) > div > div:nth-child(1) > div > div.jobs-unified-top-card__content--two-pane > div.mt2 > span.jobs-unified-top-card__subtitle-primary-grouping.mr2.t-black > span.jobs-unified-top-card__bullet')[0].get_text().strip()\n",
    "                                    locations.append(location)\n",
    "                                except IndexError:\n",
    "                                    locations.append('Unknown')\n",
    "                                    #print('location error')\n",
    "                                try:\n",
    "                                    modality = soup.select('span.jobs-unified-top-card__subtitle-primary-grouping.mr2.t-black > span.jobs-unified-top-card__workplace-type')[0].get_text()\n",
    "                                    modalities.append(modality)\n",
    "                                except IndexError:\n",
    "                                    modalities.append('Unknown')\n",
    "                                    #print('modality error')\n",
    "                                try:\n",
    "                                    description = soup.select('#job-details > span')[0].get_text()\n",
    "                                    descriptions.append(description)\n",
    "                                except IndexError:\n",
    "                                    descriptions.append('Unknown')\n",
    "                                    #print('description error')\n",
    "                        except NoSuchElementException:\n",
    "                            driver.save_screenshot(f\"{random.randint(0, 100)}.png\")\n",
    "                    except StaleElementReferenceException:\n",
    "                        driver.save_screenshot(f\"{random.randint(0, 100)}.png\")\n",
    "                time.sleep(random.randint(1, 2))\n",
    "    driver.quit()\n",
    "    df = pd.DataFrame({'title': titles, 'company': companies, 'location': locations,\n",
    "                  'modality': modalities, 'description': descriptions})\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b940391",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst = data_analyst()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e3a78c",
   "metadata": {},
   "source": [
    "## Data scientist positions published last month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b553f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_scientist():\n",
    "    driver()\n",
    "    linkedin_login()\n",
    "    titles = []\n",
    "    companies = []\n",
    "    locations = []\n",
    "    modalities = []\n",
    "    descriptions = []\n",
    "    for i in tqdm(range(0, 976, 25)):\n",
    "        driver.get(f'''https://www.linkedin.com/jobs/search/?f_TPR=r2592000&geoId=107025191&keywords=data%20scientist&location=Barcelona%2C%20Catalonia%2C%20Spain&start={i}''')\n",
    "        time.sleep(random.randint(3, 5))\n",
    "        all_listings = []\n",
    "        keep_scrolling = True\n",
    "\n",
    "        while keep_scrolling:\n",
    "            listings = driver.find_elements(By.CSS_SELECTOR,\".job-card-list__title\")\n",
    "            if set(listings) == set(all_listings):\n",
    "                keep_scrolling = False\n",
    "            else:\n",
    "                new_listings = list(set(listings) - set(all_listings))\n",
    "                #print(len(new_listings))\n",
    "                for listing in new_listings:\n",
    "                    all_listings.append(listing)\n",
    "                    try:\n",
    "                        driver.execute_script(\"arguments[0].scrollIntoView({behavior: 'smooth'});\", listing)\n",
    "                        time.sleep(random.randint(1, 3))\n",
    "                        listing.click()\n",
    "                        time.sleep(random.randint(2, 5))\n",
    "                        page_source = driver.page_source\n",
    "                        soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "                        try:\n",
    "                            title = driver.find_element(By.XPATH, \"//*[starts-with(@id, 'ember')]/h2\").text\n",
    "                            if 'data' in title.lower() or 'datos' in title.lower():\n",
    "                                titles.append(title)\n",
    "                                try:\n",
    "                                    company = driver.find_element(By.XPATH, \"//*[contains(@class, 'ember-view t-black t-normal')]\").text\n",
    "                                    companies.append(company)\n",
    "                                except NoSuchElementException:\n",
    "                                    companies.append('Unknown')\n",
    "                                    #driver.save_screenshot(\"screenshot.png\")\n",
    "                                try:\n",
    "                                    location = soup.select('body > div.application-outlet > div.authentication-outlet > div.job-search-ext > div.jobs-search-two-pane__wrapper > div > section.jobs-search__right-rail > div > div > div:nth-child(1) > div > div:nth-child(1) > div > div.jobs-unified-top-card__content--two-pane > div.mt2 > span.jobs-unified-top-card__subtitle-primary-grouping.mr2.t-black > span.jobs-unified-top-card__bullet')[0].get_text().strip()\n",
    "                                    locations.append(location)\n",
    "                                except IndexError:\n",
    "                                    locations.append('Unknown')\n",
    "                                    #print('location error')\n",
    "                                try:\n",
    "                                    modality = soup.select('span.jobs-unified-top-card__subtitle-primary-grouping.mr2.t-black > span.jobs-unified-top-card__workplace-type')[0].get_text()\n",
    "                                    modalities.append(modality)\n",
    "                                except IndexError:\n",
    "                                    modalities.append('Unknown')\n",
    "                                    #print('modality error')\n",
    "                                try:\n",
    "                                    description = soup.select('#job-details > span')[0].get_text()\n",
    "                                    descriptions.append(description)\n",
    "                                except IndexError:\n",
    "                                    descriptions.append('Unknown')\n",
    "                                    #print('description error')\n",
    "                        except NoSuchElementException:\n",
    "                            driver.save_screenshot(f\"{random.randint(0, 100)}.png\")\n",
    "                    except StaleElementReferenceException:\n",
    "                        driver.save_screenshot(f\"{random.randint(0, 100)}.png\")\n",
    "                time.sleep(random.randint(1, 2))\n",
    "    driver.quit()\n",
    "    df = pd.DataFrame({'title': titles, 'company': companies, 'location': locations,\n",
    "                  'modality': modalities, 'description': descriptions})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d15398",
   "metadata": {},
   "outputs": [],
   "source": [
    "scientist = data_scientist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cebe2ae",
   "metadata": {},
   "source": [
    "## Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b27c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([analyst, scientist]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17d343e",
   "metadata": {},
   "source": [
    "## Dropping duplicates & saving the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43528b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 412 entries, 0 to 411\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   title        412 non-null    object\n",
      " 1   company      412 non-null    object\n",
      " 2   location     412 non-null    object\n",
      " 3   modality     412 non-null    object\n",
      " 4   description  412 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 16.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b77a2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('analyst_scientist_bcn_last_month_clean.csv', index=None, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
